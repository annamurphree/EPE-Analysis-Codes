"""
Created on Fri Jun 26 15:04:15 2020

@author: Anna Murphree (annammurphree@gmail.com)
For Summer 2020 Internship with Dr. Yaping Zhou

This code opens 2D variable average files generated by get_stats and plots them.
"""
def plot_stats(axs, n1, n2, v1, v2s, v2p, v2e, var1, scale=10):
    import numpy as np
    axs[n1,n2].scatter(v2s, v1, color='red', alpha=0.5, label=r't$_{start}$', s=scale)
    axs[n1,n2].scatter(v2p, v1, color='blue', alpha=0.5, label=r't$_{peak}$', s=scale)
    axs[n1,n2].scatter(v2e, v1, color='green', alpha=0.5, label=r't$_{end}$', s=scale)
    axs[n1,n2].set_ylim([np.nanmin(v1)-np.nanstd(v1),np.nanmax(v1)+np.nanstd(v1)])
    axs[n1,n2].set_xlim([np.nanmin(v2p)-np.nanstd(v2p),np.nanmax(v2p)+np.nanstd(v2p)])
    #axs[0,0].set(xlabel='Event Duration (hours)', ylabel=r'1000 * QV2M Average (kg kg$^{-1}$)')
    if n1 == 0:
        axs[n1,n2].set_title(r'%s'%(var1), fontsize=12)

def percent_plot(arr, params, data, var, ysn, dlimb, dlima):
    import numpy as np
    from netCDF4 import Dataset
    import matplotlib.pyplot as plt
    # find percentiles of rain volume (input arr):
    #pers = [90, 80, 70, 60, 50, 40, 30, 20, 10, 1, 0.1, 0.01, 0.001]
    e90 = arr[(np.abs(arr - np.percentile(arr, 90))).argmin()]
    e80 = arr[(np.abs(arr - np.percentile(arr, 80))).argmin()]
    e70 = arr[(np.abs(arr - np.percentile(arr, 70))).argmin()]
    e60 = arr[(np.abs(arr - np.percentile(arr, 60))).argmin()]
    e50 = arr[(np.abs(arr - np.percentile(arr, 50))).argmin()]
    e40 = arr[(np.abs(arr - np.percentile(arr, 40))).argmin()]
    e30 = arr[(np.abs(arr - np.percentile(arr, 30))).argmin()]
    e20 = arr[(np.abs(arr - np.percentile(arr, 20))).argmin()]
    e10 = arr[(np.abs(arr - np.percentile(arr, 10))).argmin()]
    e1 = arr[(np.abs(arr - np.percentile(arr, 1))).argmin()]
    e01 = arr[(np.abs(arr - np.percentile(arr, 0.1))).argmin()]
    e001 = arr[(np.abs(arr - np.percentile(arr, 0.01))).argmin()]
    e0001 = arr[(np.abs(arr - np.percentile(arr, 0.001))).argmin()]
    
    # find the index of the events where the rain volume is those percentiles:
    i90 = [int(event[28]) for event in params if event[6] == e90]
    i80 = [int(event[28]) for event in params if event[6] == e80]
    i70 = [int(event[28]) for event in params if event[6] == e70]
    i60 = [int(event[28]) for event in params if event[6] == e60]
    i50 = [int(event[28]) for event in params if event[6] == e50]
    i40 = [int(event[28]) for event in params if event[6] == e40]
    i30 = [int(event[28]) for event in params if event[6] == e30]
    i20 = [int(event[28]) for event in params if event[6] == e20]
    i10 = [int(event[28]) for event in params if event[6] == e10]
    i1 = [int(event[28]) for event in params if event[6] == e1]
    i01 = [int(event[28]) for event in params if event[6] == e01]
    i001 = [int(event[28]) for event in params if event[6] == e001]
    i0001 = [int(event[28]) for event in params if event[6] == e0001]
    
    inds = [i90, i80, i70, i60, i50, i40, i30, i20, i10, i1, i01, i001, i0001]
    #print(percents)
    dat = Dataset(data, mode='r')
    qs = []
    qp = []
    qe = []
    qst = []
    qpt = []
    qet = []
    # for each percentile, find the var averages/stddevs (matched by index):
    for i in inds:
        ds = [event[0] for event in params if event[28] == i][0]
        de = [event[1] for event in params if event[28] == i][0]
        tp = [event[34] for event in params if event[28] == i][0]
        #print(ds, de, tp)
        tstart = int((ds - int(ds))*24)
        tmax_days = ds + (tp/24)
        tmax_hrs = int((tmax_days - int(tmax_days))*24)
        tend = int((de - int(de))*24)
        
        qv2ms = dat.variables[f'{var}'][i,tstart,0]
        qv2mp = dat.variables[f'{var}'][i,tmax_hrs,0]
        qv2me = dat.variables[f'{var}'][i,tend,0]
        qs.append(qv2ms)
        qp.append(qv2mp)
        qe.append(qv2me)
        qv2mst = dat.variables[f'{var}'][i,tstart,1]
        qv2mpt = dat.variables[f'{var}'][i,tmax_hrs,1]
        qv2met = dat.variables[f'{var}'][i,tend,1]
        qst.append(qv2mst)
        qpt.append(qv2mpt)
        qet.append(qv2met)
        
    xlabs = ['90', '80', '70', '60', '50', '40', '30', '20', '10', '1', '0.1', '0.01', '0.001']
    xs = np.arange(13)
    plt.xticks(xs, xlabs)
    plt.plot(xs, qs, color='r', alpha=0.5, label=r't$_{start}$')
    plt.errorbar(xs, qs, yerr=qst)
    plt.plot(xs, qp, color='b', alpha=0.5, label=r't$_{peak}$')
    plt.errorbar(xs, qp, yerr=qpt)
    plt.plot(xs, qe, color='g', alpha=0.5, label=r't$_{end}$')
    plt.errorbar(xs, qe, yerr=qet)
    plt.ylabel(f'{var}')
    plt.xlabel('Rain Volume Percentile')
    plt.legend()
    plt.tight_layout(pad=0.1)
    plt.savefig(f'{ysn}_percentplot_{var}_dlimb{dlimb}_dlima{dlima}.png')
    plt.show()
''
def open_event_info(file, stats, ysn, dlimb=0, dlima=1000):
    from netCDF4 import Dataset
    import numpy as np
    #import matplotlib.pyplot as plt
    
    # open the event stats from IMERG:
    stat = Dataset(stats, mode='r')
    params = stat.variables['event_parameters'][:]
    
    # create holders for event stats & averages:
    duras = []
    vols = []
    areas = []
    vmax_lats = []
    vmax_lons = []
    vavg_lats = []
    vavg_lons = []
    qv2ms_avg = []
    qv2mp_avg = []
    qv2me_avg = []
    q250s_avg = []
    q250p_avg = []
    q250e_avg = []
    q500s_avg = []
    q500p_avg = []
    q500e_avg = []
    q850s_avg = []
    q850p_avg = []
    q850e_avg = []
    u500s_avg = []
    u500p_avg = []
    u500e_avg = []
    v500s_avg = []
    v500p_avg = []
    v500e_avg = []
    
    data = Dataset(file, mode='r')
    indices = len(data.variables['index'])
    #print(data.variables)
    
    for event in params:
        dstart = event[0]    # start time (days) of the year
        dend = event[1]      # end time (days) of the year
        year = event[22]     # year of event, which I add 1 to because the stats files are a year off
        year = int(year + 1)
        #print('Dates: ',dstart,'-', dend, ',',year)
        #long = event[2]      # longitude (deg East)
        #print('IMERG long: ',long)
        #lati = event[3]      # latitude (deg North)
        #print('IMERG lat: ',lati)
        dura = event[4]      # Extreme event duration [hours]
        vol = event[6]       # Extreme event rain volume - Heavy rain only [m^3]
        area = event[7]      # Extreme event total area - Heavy rain only [km^2]
        vmax_lat = event[18] # Maximum latitude component of system velocity [km hr^-1]
        vmax_lon = event[19] # Maximum longitude component of system velocity [km hr^-1]
        vavg_lat = event[20] # Mean latitude component of system velocity [km hr^-1]
        vavg_lon = event[21] # Mean longitude component of system velocity [km hr^-1]
        
        tmax = event[34]    # time into event of max rain volume (hours) 
        index = int(event[28])   # event index #
        #print('Index: ',index)
        tstart = int((dstart - int(dstart))*24)
        #print('Start hour:',tstart)
        tmax_days = dstart + (tmax/24)
        tmax_hrs = int((tmax_days - int(tmax_days))*24)
        #print('Peak hour: ',tmax_hrs)
        tend = int((dend - int(dend))*24)
        
        # small: dura < 6hrs       (dlimb=0,  dlima=6)
        # med  : 6 <= dura < 24hrs (dlimb=6,  dlima=24)
        # big  : dura > 24hrs      (dlimb=24, dlima=inf)
        #if index < indices and (dlimb <= dura <= dlima):
        if index < indices:
            qtest0 = data.variables['QV2M'][index,1,0,0]
            qtest1 = data.variables['QV2M'][index,2,0,0]
            qtest2 = data.variables['QV2M'][index,3,0,0]
            #qtest0 = data.variables['QV2M'][index,tstart,0]
            #qtest1 = data.variables['QV2M'][index,tmax_hrs,0]
            #qtest2 = data.variables['QV2M'][index,tend,0]
            #print(qtest2)
            if qtest0 != np.nan and qtest1 != np.nan and qtest2 != np.nan:
                duras.append(dura)
                vols.append(vol)
                areas.append(area)
                vmax_lats.append(vmax_lat)
                vmax_lons.append(vmax_lon)
                vavg_lats.append(vavg_lat)
                vavg_lons.append(vavg_lon)
                #print(vavg_lon)
                qv2ms_avg.append(data.variables['QV2M'][index,tstart,0])
                qv2mp_avg.append(data.variables['QV2M'][index,tmax_hrs,0])
                qv2me_avg.append(data.variables['QV2M'][index,tend,0])
                q250s_avg.append(data.variables['Q250'][index,tstart,0])
                q250p_avg.append(data.variables['Q250'][index,tmax_hrs,0])
                q250e_avg.append(data.variables['Q250'][index,tend,0])
                q500s_avg.append(data.variables['Q500'][index,tstart,0])
                q500p_avg.append(data.variables['Q500'][index,tmax_hrs,0])
                q500e_avg.append(data.variables['Q500'][index,tend,0])
                q850s_avg.append(data.variables['Q850'][index,tstart,0])
                q850p_avg.append(data.variables['Q850'][index,tmax_hrs,0])
                q850e_avg.append(data.variables['Q850'][index,tend,0])
                u500s_avg.append(data.variables['U500'][index,tstart,0])
                u500p_avg.append(data.variables['U500'][index,tmax_hrs,0])
                u500e_avg.append(data.variables['U500'][index,tend,0])
                v500s_avg.append(data.variables['V500'][index,tstart,0])
                v500p_avg.append(data.variables['V500'][index,tmax_hrs,0])
                v500e_avg.append(data.variables['V500'][index,tend,0])
                
                #data.close()
    '''
    qv2ms_avg = [np.round(num, 10) for num in qv2ms_avg]
    qv2mp_avg = [np.round(num, 10) for num in qv2mp_avg]
    qv2me_avg = [np.round(num, 10) for num in qv2me_avg]
    q250s_avg = [np.round(num, 10) for num in q250s_avg]
    q250p_avg = [np.round(num, 10) for num in q250p_avg]
    q250e_avg = [np.round(num, 10) for num in q250e_avg]
    q500s_avg = [np.round(num, 10) for num in q500s_avg]
    q500p_avg = [np.round(num, 10) for num in q500p_avg]
    q500e_avg = [np.round(num, 10) for num in q500e_avg]
    q850s_avg = [np.round(num, 10) for num in q850s_avg]
    q850p_avg = [np.round(num, 10) for num in q850p_avg]
    q850e_avg = [np.round(num, 10) for num in q850e_avg]
    u500s_avg = [np.round(num, 10) for num in u500s_avg]
    u500p_avg = [np.round(num, 10) for num in u500p_avg]
    u500e_avg = [np.round(num, 10) for num in u500e_avg]
    v500s_avg = [np.round(num, 10) for num in v500s_avg]
    v500p_avg = [np.round(num, 10) for num in v500p_avg]
    v500e_avg = [np.round(num, 10) for num in v500e_avg]
    '''
    percent_plot(vols, params, file, 'QV2M', ysn, dlimb, dlima)
    percent_plot(vols, params, file, 'Q250', ysn, dlimb, dlima)
    percent_plot(vols, params, file, 'Q500', ysn, dlimb, dlima)
    percent_plot(vols, params, file, 'Q850', ysn, dlimb, dlima)
    percent_plot(vols, params, file, 'U500', ysn, dlimb, dlima)
    percent_plot(vols, params, file, 'V500', ysn, dlimb, dlima)
    
    '''
    fig, axs = plt.subplots(2, 6, figsize=(30,10), sharey='row')
    #areas[areas > 1e8] = np.nan
    #areas = [np.nan for num in areas if num > 1e8]
    plot_stats(axs, 0, 0, vavg_lats, qv2ms_avg, qv2mp_avg, qv2me_avg, 'QV2M Avg (kg kg$^{-1}$)')
    plot_stats(axs, 0, 1, vavg_lats, q250s_avg, q250p_avg, q250e_avg, 'Q250 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 0, 2, vavg_lats, q500s_avg, q500p_avg, q500e_avg, 'Q500 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 0, 3, vavg_lats, q850s_avg, q850p_avg, q850e_avg, 'Q850 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 0, 4, vavg_lats, u500s_avg, u500p_avg, u500e_avg, 'U500 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 0, 5, vavg_lats, v500s_avg, v500p_avg, v500e_avg, 'V500 Avg (kg kg$^{-1}$)')
    axs[0,0].legend(fontsize=12)
    axs[0,0].set_ylabel('V$_{avg,lats}$ (km s$^{-1}$)')
    plot_stats(axs, 1, 0, vavg_lons, qv2ms_avg, qv2mp_avg, qv2me_avg, 'QV2M Avg (kg kg$^{-1}$)')
    plot_stats(axs, 1, 1, vavg_lons, q250s_avg, q250p_avg, q250e_avg, 'Q250 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 1, 2, vavg_lons, q500s_avg, q500p_avg, q500e_avg, 'Q500 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 1, 3, vavg_lons, q850s_avg, q850p_avg, q850e_avg, 'Q850 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 1, 4, vavg_lons, u500s_avg, u500p_avg, u500e_avg, 'U500 Avg (kg kg$^{-1}$)')
    plot_stats(axs, 1, 5, vavg_lons, v500s_avg, v500p_avg, v500e_avg, 'V500 Avg (kg kg$^{-1}$)')
    axs[1,0].set_ylabel('V$_{avg,lons}$ (km s$^{-1}$)')
    plt.show()
    fig.savefig(f'{ysn}_scatplots_dlimb{dlimb}_dlima{dlima}_vels.png')
    ''
    fig1, axs1 = plt.subplots(2, 6, figsize=(30,10), sharey='row')
    #areas[areas > 1e8] = np.nan
    #areas = [np.nan for num in areas if num > 1e8]
    plot_stats(axs1, 0, 0, areas, qv2ms_avg, qv2mp_avg, qv2me_avg, 'QV2M Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 0, 1, areas, q250s_avg, q250p_avg, q250e_avg, 'Q250 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 0, 2, areas, q500s_avg, q500p_avg, q500e_avg, 'Q500 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 0, 3, areas, q850s_avg, q850p_avg, q850e_avg, 'Q850 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 0, 4, areas, u500s_avg, u500p_avg, u500e_avg, 'U500 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 0, 5, areas, v500s_avg, v500p_avg, v500e_avg, 'V500 Avg (kg kg$^{-1}$)')
    axs1[0,0].legend(fontsize=12)
    axs1[0,0].set_ylabel('Area (km$^2$)')
    plot_stats(axs1, 1, 0, vols, qv2ms_avg, qv2mp_avg, qv2me_avg, 'QV2M Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 1, 1, vols, q250s_avg, q250p_avg, q250e_avg, 'Q250 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 1, 2, vols, q500s_avg, q500p_avg, q500e_avg, 'Q500 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 1, 3, vols, q850s_avg, q850p_avg, q850e_avg, 'Q850 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 1, 4, vols, u500s_avg, u500p_avg, u500e_avg, 'U500 Avg (kg kg$^{-1}$)')
    plot_stats(axs1, 1, 5, vols, v500s_avg, v500p_avg, v500e_avg, 'V500 Avg (kg kg$^{-1}$)')
    axs1[1,0].set_ylabel('Volume (m$^3$)')
    plt.show()
    fig1.savefig(f'{ysn}_scatplots_dlimb{dlimb}_dlima{dlima}_areavol.png')
    ''
    plot_stats(axs, 1, 6, areas, q500s_avg, q500p_avg, q500e_avg, 
               'Area (km$^2$)', 'Q500 Avg (kg kg$^{-1}$)', duras)
    plot_stats(axs, 0, 1, vols, q500s_avg, q500p_avg, q500e_avg, 
               'Volume (m$^3$)', 'Q500 Avg (kg kg$^{-1}$)', duras)
    plot_stats(axs, 0, 2, areas, q500s_avg, q500p_avg, q500e_avg, 
               'Area (km$^2$)', 'Q500 Avg (kg kg$^{-1}$)', duras)
    plot_stats(axs, 0, 0, duras, q850s_avg, q850p_avg, q850e_avg, 
               'Duration (hrs)', 'Q850 Avg (kg kg$^{-1}$)', duras)
    plot_stats(axs, 0, 1, vols, q850s_avg, q850p_avg, q850e_avg, 
               'Volume (m$^3$)', 'Q850 Avg (kg kg$^{-1}$)', duras)
    plot_stats(axs, 0, 2, areas, q850s_avg, q850p_avg, q850e_avg, 
               'Area (km$^2$)', 'Q850 Avg (kg kg$^{-1}$)', duras)
    
    ''
    import pandas as pd
    import seaborn as sns
    sns.set(style="ticks", color_codes=True)
    ''
    dfs = pd.DataFrame({'Duration': duras, 'QV2Ms_Avg': qv2ms_avg,'Q250s_Avg': q250s_avg, 
                        'Q500s_Avg': q500s_avg, 'U500s_Avg': u500s_avg,
                        'V500s_Avg': v500s_avg, 'Area': areas})
    
    pairs = sns.pairplot(dfs, height=3)
    pairs.axes[2,0].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairs.axes[2,1].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairs.axes[2,3].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairs.axes[2,4].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairs.axes[2,5].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairs.axes[2,6].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairs.axes[3,0].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairs.axes[3,1].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairs.axes[3,2].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairs.axes[3,4].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairs.axes[3,5].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairs.axes[3,6].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    plt.show()
    pairs.savefig(f'{ysn}_pairplots_s_dlimb{dlimb}_dlima{dlima}.png')
    ''
    dfp = pd.DataFrame({'Duration': duras, 'QV2Mp_Avg': qv2mp_avg,'Q250p_Avg': q250p_avg, 
                        'Q500s_Avg': q500p_avg, 'U500p_Avg': u500p_avg,
                        'V500s_Avg': v500p_avg, 'Area': areas})
    #print(dfp)
    pairp = sns.pairplot(dfp, height=3)
    pairp.axes[2,0].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairp.axes[2,1].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairp.axes[2,3].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairp.axes[2,4].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairp.axes[2,5].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairp.axes[2,6].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    pairp.axes[3,0].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairp.axes[3,1].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairp.axes[3,2].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairp.axes[3,4].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairp.axes[3,5].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    pairp.axes[3,6].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    plt.show()
    pairp.savefig(f'{ysn}_pairplots_p_dlimb{dlimb}_dlima{dlima}.png')
    
    dfe = pd.DataFrame({'Duration': duras, 'QV2Me_Avg': qv2me_avg,'Q250e_Avg': q250e_avg, 
                        'Q500e_Avg': q500e_avg, 'U500e_Avg': u500e_avg,
                        'V500s_Avg': v500e_avg, 'Area': areas})
    paire = sns.pairplot(dfe, height=3)
    paire.axes[2,0].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    paire.axes[2,1].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    paire.axes[2,3].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    paire.axes[2,4].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    paire.axes[2,5].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    paire.axes[2,6].set_ylim([np.nanmin(q250s_avg)-np.nanstd(q250s_avg),np.nanmax(q250s_avg)+np.nanstd(q250s_avg)])
    paire.axes[3,0].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    paire.axes[3,1].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    paire.axes[3,2].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    paire.axes[3,4].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    paire.axes[3,5].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    paire.axes[3,6].set_ylim([np.nanmin(q500s_avg)-np.nanstd(q500s_avg),np.nanmax(q500s_avg)+np.nanstd(q500s_avg)])
    plt.show()
    paire.savefig(f'{ysn}_pairplots_e_dlimb{dlimb}_dlima{dlima}.png')
    
    dfv = pd.DataFrame({'V_Avg Lats': vavg_lats, 'V_Avg Lons': vavg_lons,
                        'U500s_Avg': u500s_avg,'V500s_Avg': v500s_avg, 
                        'U500p_Avg': u500p_avg,'V500p_Avg': v500p_avg, 
                        'U500e_Avg': u500e_avg,'V500e_Avg': v500e_avg})
    
    pairv = sns.pairplot(dfv, height=3)
    pairv.savefig(f'{ysn}_pairplots_v_dlimb{dlimb}_dlima{dlima}.png')
    '''
    
#open_event_info('2016_JJA_var_avgs.nc4', 'extreme_event_stats_2016_JJA.nc')